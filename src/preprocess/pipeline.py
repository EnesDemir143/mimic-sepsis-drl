"""
MIMIC-IV Sepsis DRL â€” Polars Lazy Preprocessing Pipeline (Memory-Optimized)
===========================================================================
Ham chartevents + labevents verilerini:
  1. itemid bazlÄ± filtrele
  2. icustays ile birleÅŸtir (stay_id ata)
  3. Saatlik bloklara yuvarla  (hourly binning)
  4. Tek-geÃ§iÅŸli group_by + conditional aggregation (pivot-free, join-free)
  5. Vitals + Labs tek join ile birleÅŸtir
  6. Forward-fill (stay_id bazÄ±nda)
  7. Parquet'e yaz (streaming sink)

Ã–nceki versiyon her feature iÃ§in ayrÄ± LazyFrame oluÅŸturup N-way full join
yapÄ±yordu â†’ bellek patlamasÄ±na neden oluyordu (~60GB).
Bu versiyon tek group_by ile tÃ¼m feature'larÄ± Ã§Ä±karÄ±r ve sink_parquet
ile streaming yazarak belleÄŸi minimize eder.
"""

from __future__ import annotations

import time
from pathlib import Path

import polars as pl
from tqdm import tqdm

from src.preprocess.config import (
    ALL_LABS_IDS,
    ALL_VITALS_IDS,
    CHARTEVENTS_CSV,
    ICUSTAYS_CSV,
    LABEVENTS_CSV,
    LABS,
    OUT_DIR,
    OUT_PARQUET,
    VITALS,
)


# â”€â”€â”€ Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def _log(msg: str) -> None:
    """Basit zaman damgalÄ± loglama."""
    print(f"[{time.strftime('%H:%M:%S')}] {msg}")


def _build_agg_exprs(feature_map: dict[str, list[int]]) -> list[pl.Expr]:
    """
    Feature map'ten tek-geÃ§iÅŸli conditional aggregation ifadeleri oluÅŸturur.

    Her feature iÃ§in:
      when(itemid âˆˆ ids).then(valuenum).mean()  â†’  feature_name

    Bu sayede N ayrÄ± frame + N-1 full join yerine tek group_by yeterli olur.
    """
    exprs = []
    for name, ids in feature_map.items():
        expr = (
            pl.when(pl.col("itemid").is_in(ids))
            .then(pl.col("valuenum"))
            .otherwise(None)
            .mean()
            .alias(name)
        )
        exprs.append(expr)
    return exprs


# â”€â”€â”€ ICU Stays â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def load_icustays() -> pl.LazyFrame:
    """icustays tablosunu lazy scan et â€” stay_id, hadm_id, subject_id, intime."""
    _log("icustays.csv.gz okunuyor...")
    return (
        pl.scan_csv(
            ICUSTAYS_CSV,
            dtypes={"stay_id": pl.Int64, "hadm_id": pl.Int64, "subject_id": pl.Int64},
        )
        .with_columns(pl.col("intime").str.to_datetime("%Y-%m-%d %H:%M:%S"))
        .select("stay_id", "hadm_id", "subject_id", "intime")
    )


# â”€â”€â”€ Vitals (chartevents) â€” tek geÃ§iÅŸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_vitals_hourly(icustays_lf: pl.LazyFrame) -> pl.LazyFrame:
    """
    chartevents.csv.gz'den vital sign feature'larÄ±nÄ± saatlik bloklara bÃ¶l.

    Tek group_by + conditional aggregation ile tÃ¼m feature'larÄ± Ã§Ä±karÄ±r.
    N-way full join YAPILMAZ â†’ bellek dostu.
    """
    _log("chartevents.csv.gz okunuyor (vitals)...")

    chart_lf = (
        pl.scan_csv(
            CHARTEVENTS_CSV,
            dtypes={
                "stay_id": pl.Int64,
                "itemid": pl.Int64,
                "valuenum": pl.Float64,
            },
        )
        .filter(pl.col("itemid").is_in(ALL_VITALS_IDS))
        .filter(pl.col("valuenum").is_not_null())
        .with_columns(
            pl.col("charttime").str.to_datetime("%Y-%m-%d %H:%M:%S"),
        )
        .with_columns(
            pl.col("charttime").dt.truncate("1h").alias("hour_bin"),
        )
        .select("stay_id", "hour_bin", "itemid", "valuenum")
    )

    _log("Vital feature'lar oluÅŸturuluyor (tek geÃ§iÅŸ)...")
    agg_exprs = _build_agg_exprs(VITALS)

    return (
        chart_lf
        .group_by("stay_id", "hour_bin")
        .agg(agg_exprs)
    )


# â”€â”€â”€ Labs (labevents) â€” tek geÃ§iÅŸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def build_labs_hourly(icustays_lf: pl.LazyFrame) -> pl.LazyFrame:
    """
    labevents.csv.gz'den lab feature'larÄ±nÄ± saatlik bloklara bÃ¶l.

    labevents'te stay_id yok â†’ hadm_id Ã¼zerinden icustays ile join yapÄ±lÄ±r.
    Sonra tek group_by + conditional aggregation ile feature'lar Ã§Ä±karÄ±lÄ±r.
    """
    _log("labevents.csv.gz okunuyor (labs)...")

    lab_lf = (
        pl.scan_csv(
            LABEVENTS_CSV,
            dtypes={
                "hadm_id": pl.Int64,
                "itemid": pl.Int64,
                "valuenum": pl.Float64,
            },
        )
        .filter(pl.col("itemid").is_in(ALL_LABS_IDS))
        .filter(pl.col("valuenum").is_not_null())
        .filter(pl.col("hadm_id").is_not_null())
        .with_columns(
            pl.col("charttime").str.to_datetime("%Y-%m-%d %H:%M:%S"),
        )
        .with_columns(
            pl.col("charttime").dt.truncate("1h").alias("hour_bin"),
        )
    )

    # labevents â†’ icustays join (hadm_id Ã¼zerinden stay_id al)
    icu_map = icustays_lf.select("stay_id", "hadm_id", "intime")
    lab_lf = (
        lab_lf
        .join(icu_map, on="hadm_id", how="inner")
        .filter(pl.col("charttime") >= pl.col("intime"))
        .select("stay_id", "hour_bin", "itemid", "valuenum")
    )

    _log("Lab feature'lar oluÅŸturuluyor (tek geÃ§iÅŸ)...")
    agg_exprs = _build_agg_exprs(LABS)

    return (
        lab_lf
        .group_by("stay_id", "hour_bin")
        .agg(agg_exprs)
    )


# â”€â”€â”€ Forward-Fill & Sink â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def merge_and_forward_fill(
    vitals_lf: pl.LazyFrame,
    labs_lf: pl.LazyFrame,
    out_path: Path = OUT_PARQUET,
) -> None:
    """
    Vitals + Labs tablosunu birleÅŸtir, sÄ±rala, forward-fill uygula, parquet'e yaz.
    Sadece tek bir full join yapÄ±lÄ±r (vitals â†” labs).
    """
    _log("Vitals + Labs birleÅŸtiriliyor...")

    feature_cols = list(VITALS.keys()) + list(LABS.keys())

    combined = (
        vitals_lf
        .join(labs_lf, on=["stay_id", "hour_bin"], how="full", coalesce=True)
        .sort("stay_id", "hour_bin")
    )

    # Forward-fill: her stay_id grubunda, her feature sÃ¼tununda
    _log("Forward-fill uygulanÄ±yor...")
    combined = combined.with_columns(
        [
            pl.col(c).forward_fill().over("stay_id").alias(c)
            for c in feature_cols
        ]
    )

    out_path.parent.mkdir(parents=True, exist_ok=True)

    # Streaming sink ile parquet'e yaz â€” collect YAPILMAZ, bellek dostu
    _log(f"Parquet'e yazÄ±lÄ±yor (streaming) â†’ {out_path}")
    try:
        combined.sink_parquet(out_path)
        _log("âœ… Pipeline tamamlandÄ± (streaming sink)!")
    except Exception:
        # sink_parquet bazÄ± join/sort kombinasyonlarÄ±nda desteklenmeyebilir
        # Bu durumda low_memory collect ile fallback yap
        _log("âš ï¸  sink_parquet desteklenmiyor, low_memory collect ile yazÄ±lÄ±yor...")
        df = combined.collect(streaming=True)
        df.write_parquet(out_path)
        _log(f"âœ… Pipeline tamamlandÄ±!  SatÄ±r: {df.shape[0]:,}  |  SÃ¼tun: {df.shape[1]}")


# â”€â”€â”€ Pipeline Orchestrator â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def run_pipeline() -> None:
    """Ana pipeline'Ä± Ã§alÄ±ÅŸtÄ±r."""
    _log("=" * 60)
    _log("  MIMIC-IV Sepsis DRL â€” Faz 1 Preprocessing")
    _log("=" * 60)

    steps = tqdm(
        ["icustays", "vitals", "labs", "merge & forward-fill"],
        desc="ðŸš€ Pipeline",
        unit="step",
    )

    steps.set_postfix(stage="icustays")
    icustays_lf = load_icustays()
    steps.update(1)

    steps.set_postfix(stage="vitals")
    vitals_lf = build_vitals_hourly(icustays_lf)
    steps.update(1)

    steps.set_postfix(stage="labs")
    labs_lf = build_labs_hourly(icustays_lf)
    steps.update(1)

    steps.set_postfix(stage="merge & write")
    merge_and_forward_fill(vitals_lf, labs_lf)
    steps.update(1)
    steps.close()
